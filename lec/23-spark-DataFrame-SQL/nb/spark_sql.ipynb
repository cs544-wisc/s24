{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9f9791-df33-4cdb-b08e-d6a07bf3c048",
   "metadata": {},
   "source": [
    "### Spark DataFrames + SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749e5dc-b62b-446b-a5f0-16f7bd080716",
   "metadata": {},
   "source": [
    "## WARNING: do not run this notebook without swap enabled and make sure that you have sufficient RAM (`htop`) before you run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0448d-c1c0-41bb-a83a-cddcc81bfb1d",
   "metadata": {},
   "source": [
    "Add swap space (caching for anonymous data):\n",
    "1. `sudo fallocate -l 1G /swapfile`\n",
    "2. `sudo chmod g-r /swapfile`\n",
    "3. `sudo chmod o-r /swapfile`\n",
    "4. `sudo mkswap /swapfile`\n",
    "5. `sudo swapon /swapfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760c4c1-c34f-4ba2-a9f4-b6857e97a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dca847-54af-4284-97d8-0682e88a6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2e1dd-99ee-49e3-b84c-667800e78a2b",
   "metadata": {},
   "source": [
    "### SF fire dataset\n",
    "\n",
    "Data source: https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669cde3-f636-494c-bdbf-7f5c19b5e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://ms.sites.cs.wisc.edu/cs544/data/sf.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205896b-940b-4556-b327-1019616f31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip sf.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067deb95-eda9-4dbc-b563-fb338cbe98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f8052-a4be-45a5-80d2-c5dc834271b2",
   "metadata": {},
   "source": [
    "Let's copy sf.csv into HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294e4e0-ab19-496c-980f-31df757e7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cp sf.csv hdfs://nn:9000/sf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41053d2b-dfb3-4510-8a5d-d92624ff88fc",
   "metadata": {},
   "source": [
    "Without schema inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004b74e-dfd7-4d31-ad01-923dda7eca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", True).load(\"hdfs://nn:9000/sf.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16c6a3-20ca-4090-be63-c4f6752c2a88",
   "metadata": {},
   "source": [
    "With schema inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13af16-6129-44ad-aae8-6f1ac317505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .load(\"hdfs://nn:9000/sf.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd4e90-2ae9-48fe-9f8b-f04320fcd3f7",
   "metadata": {},
   "source": [
    "### How to transform the data with functions on columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa61f9-7133-4826-bc5f-2c61d5484597",
   "metadata": {},
   "outputs": [],
   "source": [
    "col(\"Call Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edd921-3f91-4921-a9eb-676dc3b30bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr(\"Call Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472937a5-f04b-4ca1-a0e9-6f53d72c1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col(\"Call Date\")).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270eb63f-3228-4dd8-a47a-d9bef77eb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr(\"`Call Date`\")).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a26dc-5219-4bcc-b603-001d7568409a",
   "metadata": {},
   "source": [
    "`alias` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7c64e-9c44-4f44-b51c-4de0c314b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr(\"`Call Date`\").alias(\"Date\")).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85f8d7-fe0e-40ec-aa77-0893f258ea26",
   "metadata": {},
   "source": [
    "Convert date to proper format using `to_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf56571-affa-49fd-84c9-f65b7bcbc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr(\"to_date(`Call Date`, 'MM/dd/yyyy')\").alias(\"Date\")).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa3ffa-c667-4b8f-a0bb-21115c0a55fe",
   "metadata": {},
   "source": [
    "#### GOAL: create a parquet file with this data, with no spaces in the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4f9c6-eb96-4c44-9935-cbf6b5648f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col(c).alias(c.replace(\" \", \"_\")) for c in df.columns]\n",
    "columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbac3bf-9ebe-4a5f-9396-cb7cc5445a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b26848-9811-44e7-9c49-1746f0e97dc5",
   "metadata": {},
   "source": [
    "Write data to HDFS using parquet file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1cd0d4-6598-41cc-8f9e-e0d87236ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.select(columns)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"hdfs://nn:9000/sf.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8b8a8-7ed5-42c3-a8b9-9ea06e5ae50d",
   "metadata": {},
   "source": [
    "Let's check the files on HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd041e-8dcc-4411-86fb-c55a5f2050d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls hdfs://nn:9000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7614b-54ea-4332-a454-89a2fc08ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls hdfs://nn:9000/sf.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5fe47-28d7-458d-b486-53fd70cef76a",
   "metadata": {},
   "source": [
    "Let's read the data from the parquet file that we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b01a24-ecfa-4e01-9686-a6d3dbde1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"hdfs://nn:9000/sf.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f43a1f-1250-4f9e-b730-a714b71b22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57fb45-3620-493b-bacd-605970c93948",
   "metadata": {},
   "source": [
    "Why does spark use fewer partitions now? Compression feature of parquet format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f6816-9ed8-4301-a5a7-e8f2e92bd406",
   "metadata": {},
   "source": [
    "Let's remove sf.csv now from HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17bf1e-5bef-4c34-b600-bbe56219291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm hdfs://nn:9000/sf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b8d8e-4993-4a5f-94b6-ff9709563cd6",
   "metadata": {},
   "source": [
    "### HIVE View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd2ba4-1618-4e44-96bc-4518081df87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createTempView(\"calls\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c9f16-458a-4d16-a80e-dcd377bbec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"calls\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68e7bd-cbf0-4b22-a5f6-17d155996a1b",
   "metadata": {},
   "source": [
    "Let's rename \"Neighborhooods_-_Analysis_Boundaries\" to \"area\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f90e3-efd6-4a79-b7d8-7586dbb022d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed(\"Neighborhooods_-_Analysis_Boundaries\", \"area\").createOrReplaceTempView(\"calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da773d28-da67-4294-99c7-c655b40dba22",
   "metadata": {},
   "source": [
    "### `show` method\n",
    "\n",
    "- not a pretty output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347053e-ab82-4acf-8061-f7c55d312892",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a56c6-2ad9-4c22-84a3-35136a49e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"SELECT * FROM calls\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88997a-b6c1-4906-8e55-2dbc9010ed25",
   "metadata": {},
   "source": [
    "### `toPandas` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e3230-f050-4141-a4fb-fd97ba86aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM calls LIMIT 3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be66eaa-ef62-4fc0-a5c1-e02dca22f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9811c3b-f7a4-4c6a-ab32-bd13318c4609",
   "metadata": {},
   "source": [
    "### HIVE table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0585d2-2aaf-410c-97ce-2c8fe2ff67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM calls\n",
    "WHERE Call_Type LIKE 'Odor%'\n",
    "\"\"\").write.mode(\"overwrite\").saveAsTable(\"stinky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac948c-ed87-4700-81d2-a685fabd4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cc916-c59e-43f8-92f8-bdcba980669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM stinky LIMIT 3\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e3936-760e-4e03-8f76-8351e63e1cf4",
   "metadata": {},
   "source": [
    "Let's take a look at the data on HDFS.\n",
    "\n",
    "```python\n",
    "spark = (SparkSession.builder.appName(\"cs544\")\n",
    "         .master(\"spark://boss:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12804526-556e-41df-adb2-13256f253462",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls hdfs://nn:9000/user/hive/warehouse/stinky/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280c3a6-a227-4b42-a69d-837f95434ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM calls\").rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0ad9c-1b3e-4663-aad7-85c5fd59a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM stinky\").rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775846d-8996-4ae0-9f75-b8ecc29b0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef2aaa-996f-4337-9115-a345b7709bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"stinky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d17d4-8a68-465a-91a9-58f82a78014c",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f6e74-b16b-4d49-8982-257e08e8764d",
   "metadata": {},
   "source": [
    "### What are the unique area column values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f2b2c-0616-42f0-9794-3dcc7a3e72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT DISTINCT area FROM calls\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f7822-c13e-478b-890c-72b00311b12e",
   "metadata": {},
   "source": [
    "### How many calls are there per area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f0ab2-a8c2-4ea0-85ef-b12e50d4ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = spark.sql(\"\"\"\n",
    "SELECT area, COUNT(*) as count\n",
    "FROM calls\n",
    "GROUP BY area\n",
    "ORDER BY count DESC\n",
    "\"\"\").toPandas()\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15756a5d-28e9-40bb-8600-00756d798986",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.set_index(\"area\").plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb74e6d-cdda-46a8-b5ed-0bd5f6d3e2f1",
   "metadata": {},
   "source": [
    "### How many calls are there per groups/type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af81f7c-c69f-47b1-a4c6-411c65411e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT Call_Type_Group, Call_Type, COUNT(*) as count\n",
    "FROM calls\n",
    "GROUP BY Call_Type_Group, Call_Type\n",
    "\"\"\").toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d715928-444f-466b-a8a4-fd5ac243c813",
   "metadata": {},
   "source": [
    "### For each call group, what percentage of calls are represented by the biggest type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b9653-6fd4-4611-a898-a793797d0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT Call_Type_Group, MAX(count) / SUM(count)\n",
    "FROM (\n",
    "    SELECT Call_Type_Group, Call_Type, COUNT(*) as count\n",
    "    FROM calls\n",
    "    GROUP BY Call_Type_Group, Call_Type\n",
    ")\n",
    "GROUP BY Call_Type_Group\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ccffd-6d31-402b-bea2-17decd8a0e4b",
   "metadata": {},
   "source": [
    "Let's use DataFrame API to solve the same question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4e7f8-a984-4f83-babe-f583a2826d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.table(\"calls\")\n",
    " .groupby(\"Call_Type_Group\", \"Call_Type\")\n",
    " .count()\n",
    " .groupby(\"Call_Type_Group\")\n",
    " .agg(expr(\"MAX(count) / SUM(count)\").alias(\"perc\"))\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b383400-8ad3-4fa1-9d01-4db2d7743149",
   "metadata": {},
   "source": [
    "### Window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bf909-2d79-462f-afb5-f149c0e5a2bc",
   "metadata": {},
   "source": [
    "### What are three smallest call numbers for each area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e18d94-8d06-4e22-9c75-f909b873b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT area, Call_Number, row_number() OVER (PARTITION BY area ORDER BY Call_Number ASC) AS rownum\n",
    "FROM calls\n",
    "\"\"\").where(\"rownum <= 3\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
