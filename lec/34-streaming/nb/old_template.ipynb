{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4ce858-5065-4ae8-af13-d2661844f138",
   "metadata": {},
   "source": [
    "## Kafka + Spark streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e3af2-21f4-44ab-881e-6111776a7ee1",
   "metadata": {},
   "source": [
    "Building protocol buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e12da1-6216-41e1-beec-eae2d52c4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m grpc_tools.protoc -I=. --python_out=. animals.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e74c81-d584-4504-9ef5-2c89227d3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animals_pb2 import Sighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0f722f-060b-4236-b28c-b8cd86a6bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beach: \"A\"\n",
       "animal: \"shark\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sighting(animal=\"shark\", beach=\"A\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5daff3-d47f-433f-8933-e074145b1035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x01A\\x12\\x05shark'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serialize to string\n",
    "s.SerializePartialToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e082de56-ae72-469e-96ef-bc7fe34f0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaAdminClient, KafkaProducer, KafkaConsumer\n",
    "from kafka.admin import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError\n",
    "from kafka import TopicPartition\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "from threading import Thread, Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4795de87-cde1-4065-b508-eba0528255fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = Lock()\n",
    "def Print(*args):\n",
    "    with lock:\n",
    "        print(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991749f8-7685-46f8-b633-506f0024fe1e",
   "metadata": {},
   "source": [
    "### Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1a5535-36c1-416c-8d70-7493dbf26338",
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = \"localhost:9092\"\n",
    "admin = KafkaAdminClient(bootstrap_servers=[broker])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c13340-3034-4426-83a0-863d62e03d93",
   "metadata": {},
   "source": [
    "### Creating `animals` and `animals-json` topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207f3f33-3edd-4039-9ed2-6a606e854e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic already exists\n",
      "Topic already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    admin.create_topics([NewTopic(\"animals\", num_partitions=4, replication_factor=1)])        # protobufs\n",
    "except TopicAlreadyExistsError:\n",
    "    print(\"Topic already exists\")\n",
    "    \n",
    "try:\n",
    "    admin.create_topics([NewTopic(\"animals-json\", num_partitions=4, replication_factor=1)])   # JSON\n",
    "except TopicAlreadyExistsError:\n",
    "    print(\"Topic already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102465dc-100e-49a3-bf03-52907870ba79",
   "metadata": {},
   "source": [
    "### Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf52c987-d4c2-4077-a72b-aada380c81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = [\"shark\", \"dolphin\", \"turtle\", \"seagull\", \"whale\"]\n",
    "beaches = list(\"ABCDEFGHI\")\n",
    "\n",
    "def animal_gen():\n",
    "    producer = KafkaProducer(bootstrap_servers=[broker])\n",
    "    \n",
    "    while True:\n",
    "        beach = random.choice(beaches)\n",
    "        animal = random.choice(animals)\n",
    "        s = Sighting(animal=animal, beach=beach)\n",
    "        \n",
    "        producer.send(\"animals\", value=s.SerializeToString(), key=bytes(beach, \"utf-8\"))\n",
    "        time.sleep(1)\n",
    "\n",
    "threading.Thread(target=animal_gen).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279fec4-807f-49be-9ead-1724a2dd0239",
   "metadata": {},
   "source": [
    "### Consumer\n",
    "\n",
    "### Streaming Group By (count animal occurences per beach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfd1425-ae07-4c09-85d4-e56ad659abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] {'I': 72, 'C': 74, 'B': 63, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 76, 'G': 77, 'A': 57, 'F': 78}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 57, 'F': 78}\n",
      "[0, 1] {'I': 72, 'C': 74, 'B': 63, 'D': 75, 'E': 73}\n",
      "[0, 1] {'I': 72, 'C': 75, 'B': 63, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 57, 'F': 78}\n",
      "[0, 1] {'I': 73, 'C': 75, 'B': 63, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 57, 'F': 78}\n",
      "[0, 1] {'I': 73, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 57, 'F': 78}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 57, 'F': 79}\n",
      "[0, 1] {'I': 73, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 58, 'F': 79}\n",
      "[0, 1] {'I': 73, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n",
      "[0, 1] {'I': 74, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 77, 'G': 77, 'A': 58, 'F': 79}\n",
      "[2, 3] {'H': 78, 'G': 77, 'A': 58, 'F': 79}\n",
      "[0, 1] {'I': 74, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n",
      "[2, 3] {'H': 78, 'G': 77, 'A': 58, 'F': 80}\n",
      "[0, 1] {'I': 74, 'C': 75, 'B': 64, 'D': 75, 'E': 73}\n"
     ]
    }
   ],
   "source": [
    "def beach_consumer(partitions=[]):\n",
    "    counts = {}   # key=beach, value=count\n",
    "    \n",
    "    consumer = KafkaConsumer(bootstrap_servers=[broker])\n",
    "    consumer.assign([TopicPartition(\"animals\", p) for p in partitions])\n",
    "    consumer.seek_to_beginning()\n",
    "    \n",
    "    for i in range(10):      # TODO: loop forever\n",
    "        batch = consumer.poll(1000)\n",
    "        for tp, messages in batch.items():\n",
    "            for msg in messages:\n",
    "                s = Sighting.FromString(msg.value)\n",
    "                \n",
    "                # counts dict update\n",
    "                if not s.beach in counts:\n",
    "                    counts[s.beach] = 0\n",
    "                counts[s.beach] += 1\n",
    "        \n",
    "        Print(partitions, counts)\n",
    "\n",
    "threading.Thread(target=beach_consumer, args=([0, 1],)).start()\n",
    "threading.Thread(target=beach_consumer, args=([2, 3],)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96189610-b7c7-4f65-bd7f-850b3dcc6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[0, 1] {'seagull': 83, 'dolphin': 78, 'shark': 67, 'whale': 97, 'turtle': 66}\n",
      "[0, 1] {'seagull': 83, 'dolphin': 78, 'shark': 68, 'whale': 97, 'turtle': 66}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[0, 1] {'seagull': 83, 'dolphin': 78, 'shark': 68, 'whale': 97, 'turtle': 66}\n",
      "[0, 1] {'seagull': 83, 'dolphin': 78, 'shark': 69, 'whale': 97, 'turtle': 66}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[0, 1] {'seagull': 84, 'dolphin': 78, 'shark': 69, 'whale': 97, 'turtle': 66}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[0, 1] {'seagull': 84, 'dolphin': 78, 'shark': 70, 'whale': 97, 'turtle': 66}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[0, 1] {'seagull': 84, 'dolphin': 78, 'shark': 70, 'whale': 97, 'turtle': 67}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 68}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 69}\n",
      "[0, 1] {'seagull': 84, 'dolphin': 78, 'shark': 70, 'whale': 97, 'turtle': 67}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 74, 'dolphin': 69}\n",
      "[0, 1] {'seagull': 85, 'dolphin': 78, 'shark': 70, 'whale': 97, 'turtle': 67}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 75, 'dolphin': 69}\n",
      "[0, 1] {'seagull': 85, 'dolphin': 78, 'shark': 70, 'whale': 97, 'turtle': 67}\n",
      "[2, 3] {'seagull': 64, 'whale': 60, 'turtle': 57, 'shark': 75, 'dolphin': 69}\n"
     ]
    }
   ],
   "source": [
    "def animal_consumer(partitions=[]):\n",
    "    counts = {}   # key=animal, value=count\n",
    "    \n",
    "    consumer = KafkaConsumer(bootstrap_servers=[broker])\n",
    "    consumer.assign([TopicPartition(\"animals\", p) for p in partitions])\n",
    "    consumer.seek_to_beginning()\n",
    "    for i in range(10):      # TODO: loop forever\n",
    "        batch = consumer.poll(1000)\n",
    "        for tp, messages in batch.items():\n",
    "            for msg in messages:\n",
    "                s = Sighting.FromString(msg.value)\n",
    "\n",
    "                if not s.animal in counts:\n",
    "                    counts[s.animal] = 0\n",
    "                counts[s.animal] += 1\n",
    "        Print(partitions, counts)\n",
    "threading.Thread(target=animal_consumer, args=([0, 1],)).start()\n",
    "threading.Thread(target=animal_consumer, args=([2, 3],)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448709a-f97a-4b83-b34f-7070df9b93f1",
   "metadata": {},
   "source": [
    "**Observation:** now the count will get split across both the consumers. We need to do more work if we need summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b0bcc-ab55-40a5-a186-4622ea6f49ff",
   "metadata": {},
   "source": [
    "### Spark streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69b64a-98f9-4014-a1f6-457389b088d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c206aa-56e1-4aad-b631-85c9cea0672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animal_gen_json():\n",
    "    producer = KafkaProducer(bootstrap_servers=[broker])\n",
    "\n",
    "    while True:\n",
    "        beach = random.choice(beaches)\n",
    "        animal = random.choice(animals)\n",
    "\n",
    "        value = ???\n",
    "        producer.send(\"animals-json\", value=value, key=bytes(beach, \"utf-8\"))\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "threading.Thread(target=animal_gen_json).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339f693-ab99-4e4e-8040-63033079e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session (with Kafka jar)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"demo\")\n",
    "         .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0')\n",
    "         #.config(\"spark.sql.shuffle.partitions\", 10)\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f52414-df72-48cb-b851-254a12739ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e78ed8-3587-4789-9e51-9914158513c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f3dd4-3bdc-4f2a-b89d-93e673cf7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first five rows of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b59cc6-c4c9-4acd-ad85-56ad3809763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa197550-ab9a-439d-a71f-62bab4524c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_schema = \"\"\n",
    "schema = \"\"\n",
    "\n",
    "animals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce1d54-16e0-459b-aaf5-3ad2bd04ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c84669-d54e-479b-9ffa-ab4aef9c41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e80dc-509f-4a6a-8c08-ca8b3d0d6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_df.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c43444-81f8-472f-b81c-1040de0dd58b",
   "metadata": {},
   "source": [
    "### Streaming DataFrame\n",
    "\n",
    "source => transformations => sink\n",
    "\n",
    "```\n",
    "# streaming_query = spark.readStream(????).????.writeStream(????)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e1956-a3b3-43ee-bc55-b13ac280e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", broker)\n",
    "    .option(\"subscribe\", \"animals-json\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5ed09-6c6f-4b89-b3c9-f046f4de2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87198d60-46b7-4a41-b038-5b5df8015219",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"beach string, animal string\"\n",
    "\n",
    "animals_df = (\n",
    "    \n",
    ")\n",
    "animals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c999e5e-e406-40bc-904c-e9b5c07865fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not supported for streaming\n",
    "# animals_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823de2a-39ac-4070-a021-27aaea5af87b",
   "metadata": {},
   "source": [
    "### Shark Alert Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05ed91-8f39-473b-861f-907d26ac5d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aab708c-015f-4720-84c1-7dabf2f39891",
   "metadata": {},
   "source": [
    "### How can we stop the stream?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec205b5-1b45-499b-9b82-d6d103540436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cc437-536f-4367-90ea-86f3641a6b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6369b94-565b-4a6d-a094-583e6ccb1bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba7f14da-36b5-484f-b0a6-89e93f1be4cc",
   "metadata": {},
   "source": [
    "Alternatively, we can use the variable that we used to save the streaming query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e5254-037c-4c72-970f-30dff81e54bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02f3750-8f0d-4592-a1f2-128ae6900141",
   "metadata": {},
   "source": [
    "### Animal Counter Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21fbea-6184-4e42-9b13-b6f14aaa46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_query = (\n",
    "    animals_df.groupby(\"animal\").count()\n",
    "    .writeStream\n",
    "    .format(\"console\")\n",
    "    .trigger(processingTime=\"5 seconds\")\n",
    "    .outputMode(\"append\")\n",
    ").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e0d51-782b-43c1-90cb-74329a02671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d487f-d303-490d-9476-c9ba303f92b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
